## 1、数学
### 一、高等代数知识：
1、线性空间：线性空间的由来是因为解析几何中在二维或三维空间中对向量的操作解决几何问题在物理中也有使用向量，变换等解决实际问题，它们中都有使用加法和数量乘法，当它们面对的对象不同它们运算的定义也是不同的，为了找到它们的共同点引入线性空间的概念。(在实数域或复数域中解线性方程时分别需要使用实数和复数去做计算所以引入线	性空间概念需要选定一个确定的数域做为基础)。定义：设v是一个非空集合,P是一个数域(实数域或复数域),集合v的元素间定义了一种叫加法的代数运算，对于v中任意两个元素a与b都有唯一个数r满足a+b=r;数域p和集合p之间还定义了一个乘法对数域中任一数k与v中任一元素c在v中有唯一个元素g满足g=kc;且加法与数量乘法满足下列规则：
(1)a + b = b + a;					(2)a + b + y = a + (b + y);
(3)在v中有一个元素0对于v中任一元素a都有 0 + a = a;(具有这个性质的元素0称为v的零元素，并非是0就是v的零元素)；
(4)对于v中每一个元素a都有v中的元素b使得a + b = 0;(b称为a的负元素)。
(5)1*a = a;								(6)k(ja) = (kj)a；
(7)(k+j)a = ka + ja;                					(8)k(a+b) = ka + kb;#*
就称v是数域p上的线性空间。(求是线性空间时要根据这些条件都满足才是)
 2、维数、基与坐标：[线性空间的维数]如果在线性空间v中有n个线性无光的向量,但是没有更多线性无关的向量，那么v就称为是n维的(即任意n+1个向量组合后都是线性相关的)。[基]在n维线性空间v中n个线性无关的向量e1,e2,...en称为v的一组基；[坐标]设a是v中任一向量，于是a,e1,...,en线性相关，所以a可被这组基线性表出:a=a1*e1+...+an*en，其中系数a1,a2,...an是被向量a和这组基唯一确定的这组系数就称为a在这组基下的坐标。
3、集合、映射、线性空间的同构： 集合就是指做为整体看的一堆东西,表示为：M={a|a具有的性质}
比如满足一个方差组的解的集合、对应的系数的向量。线性空间概念中的v就是一个这样的集合,再和数域结合并满足定义的计算就成了线性空间;空集为任何集合的子集。一个集合到另一个集合的使用发则称之为映射,M在映射a下的全体称为映射a下的像的集合，如果a(M)=M'就称a为映射上的满射，如果集合M中的元素不存在a(m1)=a(m2)就称a为单射，如果一个映射即是单射又是满射就称其为双射
[同构]数域p上有两个线性空间v，v',它们之间有一个双射a有如下性质：
（1）a(m+n)=a(m)+a(n)			(2)a(km)=k*a(m)	//m,n是v中两个任意向量*，k是p中任意数
满足这些条件的两个线性空间v和v‘称为同构的，而映射a称为同构映射。
4、线性变换：线性空间是某一类事物从量方面的一个抽象(比如人脸图像数据,都为数字表示),要认清客观事物就要弄清它们单个和总体的性质，不过更重要的是研究它们之间的各种联系。而线性空间中事物的联系就反映为线性空间的映射，之前说的映射是一个集合到另一个集合的法则，但我们这里是要研究一个线性空间中各元素的联系就变成了空间到自身的映射，不过这个映射稍有点特殊，所以我们称这种自身到自身的映射叫线性变换。（线性变换是线性代数的一个主要研究对象）定义如下：
如果对于线性空间v任意的元素a,b和数域p中任意k都有： €(a+b)= €(a)+ €(b)和 €(ka)=k* €(a)
则称 €为线性空间v的一个线性变换。也说成线性变换保持向量加法与数量乘法。 
5、线性变换的矩阵、特征值与特征向量：[定理1]设e1,...e3是线性空间v的一组基,a1,...an是v中任意n个向量，,存在唯一的线性变换€使€ei=ai。[定义]e1,...en是v的一组基，€是v中的一个线性变换，基向量的像可以被基线性表出，如下：
€e1=a11*e1+a21*e2+...+an1en;...€en=a1n*e1+a2n*e2+...+ann*en;(每个基成员向量用基表示出来)
用矩阵来表示就是€(e1,...en)=(e1,...en)*A。A就称为€在基e1,...en下的矩阵。为了利用矩阵来研究线性变换，对于每个给定的线性变换我们希望找到一组基使得它的矩阵有最简单的形式。所以引入特征值、特征向量的概念方便此研究(它们对线性变换的研究有基本的重要性)。
在数域t上的线性空间v中有一线性变换u，对一向量r若能找到一个值p使得ur=pr则称p是向量r的特征值，r是特征值p的一个特征向量(u*kr=p*kr因此一个特征值可对应多个特征向量而一个特征向量只能对应一个特征值)。经过推导证明(推导过程以后添加)找到一个求特征值得到公共解法：|kE-A|=0,解出所有特征值k，把么个特征值带入解出对应的向量是特征向量在基下的坐标，再用基乘以该坐标得出对应的特征向量。(线性变换本来就是用于研究线性空间内各元素与总体的联系，而这里的值p与线性变换有类似的作用，这代表其也具有代表线性空间特征的一些意义，故称其为特征值)。
6、线性子空间及其一些相关性质：属于p上线性空间v的一个非空自己和称为w称为v的一个线性子空间。
7、欧几里得空间：由来：当以几何空间中的向量做为线性空间理论的一个具体模型时能发现向量的一些度量性质，如长度、夹角等，但这在线性空间中未能得到体现。定义：(向量的度量性质都可以通过向量的内积来表示而且向量内积有明显代数性质所以在抽象的讨论中取内积做为基本概念)设v是实数域R上一线性空间，在v上定义了一个二元实函数称为内积，记为(a,b)具有以下性质：
(1)、(a,b) = (b,a);		(2)、(ka,b)=k(a,b)；	(3)、(a+b,y)=(a,y)+(b,y)
(4)、(a,a)>=0,当且仅当a = 0时(a,a) = 0；
a、b、y时线性空间v中的任意向量，k是任意实数，满足这些v就为欧几里得空间。酉(you)空间：酉空间就是在复数域上的欧式空间要求满足的性质也一样。酉矩阵：对n级复数矩阵A，用A_表示其共轭复数矩阵，若A满足AA_=A_A=E则称A为酉矩阵。
线性相关：如果向量组a1,a2,...an中有一个向量可以由其余的向量线性表出那么该向量组就称为线性相关的，否则称为线性无关。
正交向量：欧式空间v中有一组非零向量(每一个向量都不为0)如果它们两两正交(每两个相乘为0)则是正交向量。(正交向量是线性无关的，每个向量不超过n维)
标准正交基：n维欧式空间中由n个向量组成的正交向量组称为正交基，有单位向量组成的正交基称为标准正交基.(n维欧式空间中任一正交向量组都能扩充成一组正交基)
正交矩阵：若n级实数矩阵A满足A'*A=E则A称为正交矩阵。(复数域中叫酉矩阵)
### 二、概率论知识：
<i class="label1">重要前提知识</i><i class="orange">随机试验中每个可能的结果称为基本事件，所有基本事件的全体组成样本空间。</i>一个随机实验，数学上是用样本空间u、事件域v<i class="violet">(多数情况下可以认为事件域是u的全体子集，但也有部分情况下是不合理的，所以这不是一个推广)</i>和概率p来描述的，对一个事件域中的随机事件A求它的概率P(A)，是概率论的一个基本课题。<i class="green">概率与频率：概率是描述一件事发生的可能性的大小，是一个本质属性的东西。因为实验要达到足够多的次数，频率/总体值，才能稳定下来，而且现实中事件受到很多不确定因素的影响，所以频率只是近似概率，是用来计算概率的一种手段。</i>
#### 1、古典概型：
有限个样本空间，且发生的有限个基本事件w1,w2,...发生的概率是等可能的：p(w1)=p(w2)=...-p(wn)，这就是一早期概率论的古典概型，其直观且出现广泛。对于随机事件A(是k个基本事件发生的组合)，其概率：p(A)=A中所含基本事件数 / 基本事件总数 = k/n
#### 2、概率的公里化定义及概率的性质：
非负性、规范性、可列可加性。上面的古典概型的实验结果是有限的，但有些实验中实验结果是无限的(如指定面积中投点)，但实验结果为无限时会使得问题求解变得很困难。
 <i class="label2">蒙特卡罗法/随机模拟法</i>在一实验中，让一事件与某一随机数有关，通过大量实验求出频率即可求得这个未知数的近似解。
 在几何概型中事件域看似是样本空间的全体子集，但很遗憾，面积s中存在不可侧集，所以事件域只能描述成样本空间中具有面积的全体子集。
<i class="label2">全概率公式</i>设b1,b2,...,bn是一列互不相容的事件，且这些基本事件构成整个样本空间。则对任一事件A有：P(A)=∑P(bi)*P(A|bi) #*注意这个公式的前提，b1,...,bi是构成整个样本空间的，所以事件A的发生是由一些列bi事件组成的。
<i class="label2">伯努利概型</i>实验E只有两个结果A,A-。而p(A)=p,p(A-)=1-p=q;把E独立重复n次又构成了一个实验(例如抛硬币,一次抛多个改为每次抛一个)称为n重伯努利概型。
<i class="label3">泊松定理和泊松分布</i>在n重伯努利实验中，事件A在一次实验中出现的概率为pn，如果当n趋于无穷时，n*pn趋于λ，则有公式*：lim b(k;n,pn)=(λ^k / k!)*exp(-λ) #*k=0,1,...其中的公式exp(-λ)表示：e^(-λ)。这各定理适合在实验次数特别多的时候使用。这形成的分布称作是参数为λ的泊松分布(Poisson)。
<i class="label2">期望</i>在对比两个事物的好坏时(如两种品种母鸡的年产蛋量)，虽然看两者分布列也能够区分出来，但不够直观，也不够快，所以提出期望的概念(也是平时常用的平均值，不过这里的稍有点不一样而以)。[举一个例子]从工厂抽出100支手表,测出每只手表的日走时误差,分布为(支数，日走误差)(3,-2),(10,-1)...[平均日走时误差]=3*-2+10*-1+.../100(总日走误差/总支数)期中可拆分出3/100,10/100这些是在100支手表中的频率,所以原式可改为s=sum(k*1/p(k)),这个均值称为数学期望。(注意这里的期望和方差是离散型随机变量的情况)
<i class="label2">方差</i>这和小学学到的方差类似，对比一些期望分辨不出的实例。设a是一个离散型随机变量，数学期望Ea存在，如果E(a-Ea)^2存在则称该值为随机变量a的方差。
#### 3、离散型随机变量：
实验中原本只是为了求出各样本点出现的概率，但因为是实验的关系所以要统计各样本点的出现便于研究，因此实验中就出现了样本点出现次数以及对应样本点，两个变量，不过这是人为构建的。这其实就是一个函数的关系。实验E中样本点w出现的次数用e表示，而e=e(w)称为一维(实值)离散型随机变量<i class="green">(虽然是两个变量，但其描述的是一个事件所以将其称为一维的离散型随机变量)</i>。
<i class="label2">多维随机变量</i>一维随机变量是一维实值和实验结果的关系，这种情况研究简单，但多维的情况会变得更复杂。如研究一个家庭有两个小孩(男用1表示，女用0表示)，那么0和1就变成了两个离散型随机变量，表示为p(a=i,b=j)。这其实可以看作是两个基本事件0和1的组合情况，当这两者互不相容时就变成了：p(a=i,b=j)=p(a=i)*p(b=j)    *
<i class="label2">联合分布列、边际分布列</i>多个离散型随机变量的分布列表示即为联合分布列(3个及以上时无法在表中很好的表示)，联合分布列右侧，下侧对应的两个单个变量的分布称为这个联合分布列的边际分布列。
<i class="label2">泊松分布可加性</i>上面泊松定理描述中是一维随机变量的情况，而遇到多维随机变量的情况，泊松定理也有其性质对应，那就是泊松分布的可加性：设a,b是两个独立的随机变量，它们分别服从参数为λ1和λ2的泊松分布，则c=a+b服从参数为λ1+λ2的泊松分布，公式：p(c=k)=[(λ1+λ2)^k / k!] * exp(-(λ1+λ2)) #k=0,1,...。<i class="violet">注意这里的a和b是独立的，且是a+b的泊松分布，而且需要实验次数n非常巨大时可以使用。</i>
<i class="label2">二项分布、多项分布、单点分布</i>进行一个n重伯努利实验，x表示实验成功的次数，概率：
右图二项式系数，其构成的分布为二项分布。在n=1时的二项分布特例，所该分布列中只有0和1两个结果也叫两点分布。
多项分布：多项分布是二项分布的推广，先看一例：城市中按年龄分为n个组，对应的频率为p1,p2,...，现从城市中随机抽取N个人用x1,x2,...xn表示其中各age组所包含的人数，则x1,...xn服从多项分布。
X~B(N,P)定义：如果一个随机向量x=(x1,...xn)满足如下条件：(1)xi>=0(1<=i<=n),且x1+...+xn=N.(2)设m1,...mn为任意非负整数，且m1+..+mn=N,则事{x1=m1,x2=m2,...xn=mn}的概率为：
p{x1=m1,...xn=mn}=N!*p1^m1*...*pn^mn  /  m1!...mn!	(p1+p2+...+pn)=1则称随机向量x=(x1,...xn)服从多项分布，x~PN(N:P1,...Pn)
单点分布：当二项分布随机变量继续减少，也即随机变量 €只剩下一个情况时可以写成p( €=a)=1为单点分布或退化分布。
#### 4、连续型随机变量：
上面所述的都是离散型随机变量的情况，即样本空间是有限的，实验中出现的随机变量情况是有限的，但无限的情况也有很多(如测量某地气温)，这需要概率统计来解决。
举例：一个几何概型，在区间[a,b]上投点，统计其落入区间[c,d]的概率，按照离散型的情况计算分布列是：p(v(w)=w0)=p(w=w0)=lwo/(b-a)=0 #因为点没有长度，但这又是不合理的，所以需要换一种方法表示分布列。p(c<=v<=d)=(d-c)/(b-a)=>p(c<=v<=d)=p(v<=d)-p(v<=c)。定义：在样本空间u上，取值于实数域的函数v(w)，称为是样本空间u上的实值，并称：F(x)=P(v(w)<=x),x属于负无穷到正无穷。因为v(w)<=x是一种区间上连续变化的情况，因此要进一步更好的描述好连续型随机变量的分布需要借助积分的概念=>若r(x)是随机变量，F(x)是它的分布函数，如果存在函数p(x)使对任意的x有F(x)=ƒ p(y)dy(负无穷到x),ƒ表示积分,则称r(x)为连续型随机变量，F(x)为连续型分布函数，p(x)为其概率密度。<i class="green">任一随机变量的分布函数都具有如下性质：(1)单调性：若x1<x2,则F(x1)<=F(x2)。(2)有界性，(3)右连续性。</i>
<i class="label2">正太分布</i>若μ和σ(>0)是两个常数，则p(x)=exp(-(x-μ)^2 / (2*σ^2)) / σ*sqrt(2*pi) #*在-无穷～+无穷情况下该式积分为1，称其为正太密度，构成的分布函数成为正太分布，高斯常用它来刻画误差，大量实验表明，如果一个变量受大量的微小的，独立的随机因素影响则该变量一般是个正太变量。正太分布转标准正太分布的计算：p118(暂留！)
<i class="label2">连续型随机变量的期望</i>上面介绍的期望是离散型的情况，连续型随机变量情况与离散型有些区别。<i class="violet">分析：</i>设a是一个连续型随机变量，密度函数为p(x)，区间上区分点x0,x1,...xn。a落在△x=(xi,xi+1)中的概率为：p(a∈△x)=ƒ p(x)dx #ƒ 是积分<i class="green">(因为(xi,xi+1)是一个连续的区间，这种情况符合积分的形式)</i>。当△x相当小时，有p(a∈△x)=p(x)*△x #*(类似几何情况中弧形区域相当小时可看作一个矩形区域)。所以该连续型随机变量的期望：∑ x*p(x)*△x。<i class="violet">定义：</i>设a是一个连续型随机变量，密度函数为p(x)，当(-无穷,+无穷)ƒ |x|*p(x)dx < +无穷#*时称a的数学期望存在，则Ea = (-无穷,+无穷)ƒ x*p(x)dx #*<i class="green">(因为前面分析中的△x是一个非常微小的量，所以整个式子的极限就是将△x去掉，再几何积分形式来描述求和符号)</i>
<i class="label2">二维随机变量的期望</i>设(a,b)是二维连续型随机变量，密度函数为p(x,y)，又f(x,y)是二元函数，则随机变量c=f(a,b)的数学期望为：
`Ec=Ef(a,b)=(-无穷,+无穷)ƒ ƒ f(x,y)*p(x,y)dxdy#*`
<i class="label2">切比雪夫不等式</i>对于事件|a-Ea|>b发生的概率与其Da有关(因为方差反映了随机变量偏离期望的平均程度)，粗糙的说Da越大这个事件发生的概率也会越大，因此将这个直觉经过实验，严格化就得到了：对任意随机变量a，其期望Ea=b，且Da存在，则对任意的正常数c有：p(|a-b|>=c)<=Da / c^2 #这个定理还是比较官用的，我们可以求一变量偏离其均值程度的概率范围。
<i class="label2">条件期望</i>如果随机变量a在(b=y)发生的条件小的条件密度函数为p(x|y)且：`(-无穷,+无穷)ƒ|x|*p(x|y)dx<+无穷`则称`E{a|b=y}=(-无穷,+无穷)ƒ|x|*p(x|y)dx<+无穷`为a在(b=y)发生的条件下的条件数学期望，简称条件期望。
<i class="label2">特征函数</i>书中描述到用上述的求分布函数、分布密度的方法有时候使用起来很不方便(如度a,b两个随机变量，密度函数为p(a),p(b)求c=a+b的密度函数为p(c)=p(a)*p(b)*这样是对式子做了卷积运算<i class="violet">(两个函数经过一系列计算得到第卅个函数)</i>，[这里的p(a),p(b)就是密度函数]，随机变量很多时计算会变得更复杂，而傅里叶变换能把卷积运算变为乘法运算，因此这里又如傅里叶，对于p(x)的傅里叶变换是：`Œ(t)=(-无穷,+无穷)ƒ e^(i*t*x) * p(x)dx`。定义：设€是一随机变量，称`Œ(t)=E*e^(i*t*€)，-无穷<t<+无穷`是€的特征函数，所以对于离散型随机变量的特征函数为：`Œ(t)=E*e^(i*t*€)=∑e^(i*t*x) * p`。设函数p、p1、p2的傅里叶变换为s(p)、s(p1)、s(p2)，又p=p1*p2则s(p)=s(p1)*s(p2)。(还没全部理解！)
#### 5、大数定律：
上面前言中说到，频率可以用来近似概率，实验次数越多，两者就越接近，但是否能说明概率是频率的极限呢？这是大数定律和中心极限定律所要阐述的。
分析：设在n次实验中A出现的次数为μn，如果说概率是频率的极限的话就有：对任意的整数N和任给的Œ>0都有|(μn / n) - p| < Œ。但当实验是一个单点分布时即μn / n=1，而0<Œ<1-p，所以这个式子是不成立的，也说明了概率不是频率的极限，它们的具体关系如下：
<i class="label3">伯努利定理</i>设μn是n重伯努利实验中事件A出现的次数，A在每次实验中出现的概率为p，则对任意的Œ>0有：`(n→+无穷)lim P(|(μn / n)-p|<Œ)=1`#其中的证明用到切比雪夫不等式p203，具体意思就是<i class="blue">当实验次数趋于正无穷时概率和频率的差值足够小的概率为1</i>，这称为伯努利大数定律。
<i class="label3">大数定律定义</i>若€1,...,€n是随机变量序列，如果存在常数列a1,...使对任意的c>0有：`(n→+无穷)lim P(|(∑€i / n)-an|<c)=1`则称随机变量序列{€n}服从大数定律。
<i class="label3">切比雪夫大数定律</i>
<i class="label3">马尔可夫大数定律</i>
<i class="label3">辛钦大数定律</i>
#### 6、抽样、统计量：
<i class="label1">先验分布</i>在进行一次实验之前我们一般会进行猜测实验结果且我们会多多少少知道一些实验中的一些未知参数可能的值这叫先验知识，我们对该值猜测的值和这样猜测的原因构成的这个分布就是先验分布。这是在实验前进行的所以不影响实验。
<i class="label1">后验分布</i>根据样本Xde分布PO及O的先验证分布tt(o)，用概率论中求条件概率分布的方法可算出在已知X=x的条件下o的条件分布，因为这个分布是在抽样后才得到的故称为后验分布。
<i class="label1">抽样</i>在很多情况下是从总样本中抽取一批子样拿来研究，如抽取一批灯泡，统计其质量。一般是使用随机方法从中抽取n个，且每抽取一个会将其放回打乱再抽，这叫做简单随机子样(由于每次抽样的总样本空间是一样的因此保证了每个样本被抽到的概率相同，所以经常使用)。而不放回的抽样使用较少，不过在n/N <=0.1#(n是抽取的个数，N是总样本个数，且很大时适合使用)时也可以用不放回抽样代替随机字样。
<i class="label2">确定抽样数量</i>用公式来大致确定需要抽样多少合适：放回抽样情况：`n=Z*a^2 / △^2`。不放回抽样情况：`n=N*Z*a^2 / (N*△^2 + Z*a^2 )`。#a^2是总样本方差，N是总样本数，Z是置信系数，是正态分布条件下与置信水平相联系的系数，置信水平取95%，则Zα/2=1.96，可以根据表格查找其值，95.45%是2。△是误差。[参考学习地址。](https://blog.csdn.net/cgch_cn/article/details/88700419)
<i class="label2">抽样误差</i>既然是抽样计算，那与全量计算就会差距，用误差计算公式来尽量的弥补两者的差距。
放回(重复)抽样误差计算：`u = sqrt(a^2 / n)`。不放回抽样误差计算：`u = sqrt([a^2 / n] * [(N-n) / (N-1)]) `。#a^2是抽样本方差，N是总样本数，n是抽样数。
<i class="label1">统计量</i>子样是母体的反映，但子样信息不能直接用于解决研究问题，需要对子样所含信息进行数学上的加工才能拿来用，所以构造一个依赖于子样的函数即统计量来研究。一个统计量是字样的一个函数，如果子样容量为n，它也就是n个随机变量的函数，并且要求这个函数是不依赖与任何未知参数的随机变量，统计量的分布称为抽样分布。随机变量a=∑€i 是一个统计量。`即使一个统计量不依赖于任何参数，但它的分布可能是依赖于未知参数的`。
<i class="label2">一些常用统计量</i>设Œ1,...,Œn是从母体Œ中取出的容量为n的字样。
统计量：`Œ' = ∑Œ / n`称为字样均值。统计量：`s^2 = ∑(Œ - Œ')^2 / n`称为字样方差#Œ'是均值。统计量：`m = ∑(Œ - Œ')^k / n`称为字样k阶中心矩。统计量：`Œ'^k = ∑Œ^k / n`称为字样k阶矩。
<i class="label2">定理</i>设母体服从正太分布N(u,a^2)，(Œ1,...,Œn)是取自母体的一个子样，则Œ‘服从正太分布：N(u,a^2 / n)。推理在p242。
#### 7、点估计：
数理统计的基本问题是根据子样本所提供的信息，对母体分布及分布的数字特征等作出统计推断的问题，这个问题中的一类是母体分布的类型为已知，而它的某些参数为未知，这类问题称为参数估计问题。
设€1，€2,..,€n是取自母体的一个子样，我们构造一个统计量，n=(€1,...,€n)作为参数œ 的估计，统计量n为参数œ 的一个估计量，若(x1,x2,...,xn)是(€1，€2,..,€n)的一组观测值，则y=u(x1,x2,...,xn)就是œ 的一个点估计值。如果分布族中含有k个未知参数，即{f(x;œ 1,...,œ n)}则需要构造k个统计量作为各参数的估计量，这种问题又称为参数的点估计问题。
<i class="label1">矩法估计</i>
<i class="label1">极大似然估计</i>极大似然估计是求估计的另一种方法(由高斯提出)，直观想法：假设一个实验会出现若干种情况，若在一次实验中结果A出现则会认为实验条件对A有利，即A出现的概率更大。假设从容量为n的子样r1,r1,...取到观测值x1,x2,...的概率为：f(r1=x2,...)=p^x1(1-p)^(1-x1)*p^x2...
可写为：L(p)=p^(sum(xi))*(1-p)^(n-sum(xi))。根据极大似然的思想，在一次实验中取得x1,...xn的概率应该最大，即L(p)达到最大值，lnL(p)会是一个单掉增函数求其极大值：求导，令其为0后可得：p'=p'(x1,x2,...xn)=sum(xi)/n这使L(p)达到最大，称为参数p的极大似然估计。
<i class="label1">克拉默-拉奥不等式</i>
7、狄利克雷分布：
#### 8、假设检验：
<i class="label1">基本思想和概念</i>怎样在字样基础上作出一个较大把握的结论就是统计假设检验问题。把任意一个有关未知分布的假设称为**统计假设**或简称**假设**。例如在一批产品中引入了新的技术，我们要判断引入新技术后该产品是否有显著提高(一般用平均值)。那么u=1000是一个**原假设**，u>1000是一个**备选假设**(具体选哪个作为原假设要根据具体业务和情况)。<i class="green">用一个字样无法去证实一个陈诉，当去否定一个陈诉的理由就比较充分(如假设一批数据中每个值都大于10，只需要找到一个小于10的即可推翻，而不用每个都去确定)。所以统计假设检验问题的一般提法是：在给定备择假设H1下对原假设H0作出判断，若拒绝原假设H0那加意味着接受假设H1。</i>
<i class="label2">参数假设</i>在许多问题中母体的分布类型为已知，仅有一个或几个参数为未知<i class="green">(虽然类型已知，但某些参数未知，仍然算做是未知分布，所以符合上面统计假设的定义)</i>，需要对这几个参数作出假设，这种仅涉及到母体分布的未知参数的统计假设称为**参数假设**。
<i class="label2">非参数假设</i>某些情况下我们不知道母体的分布类型，只能对分布函数的类型或它的某些特征提出某种假设，称为非参数假设。如：
H0：F(x)∈ {对数正太分布簇}。H1：F(X)∈ {正太分布簇}。如果一个统计假设完全确定母体的分布，就称为**简单统计假设**，否则称为**复合统计假设**。
<i class="label1">检验法则</i>显然它应该是一个定义在子样本空间上的一个函数为依据所构成的准则，一旦子样的观察值(x1,...,xn)确定后就可以依据这个规则判断是拒绝H0还是拒绝H1，这称为一个检验法则。本质上是把字样空间划分为两个互不相交的子集c和c'(看作是一种符合两种假设特征的样本)，若字样的观测值点(x1,...,xn)∈ c则拒绝假设H0，否则拒绝H1。称这个字样空间的子集c为**检验的临界域**。
<i class="label2">两类错误</i>由于子样的随机性，判断时还是可能回放两类错误，一类是H0为真时子样观测值落入c，而按给定检验法则当拒绝H0，这是第一类错误，范第一类错误的概率称为**拒真概率**。相反称为第二类错误，发生的概率称为**受伪概率**。
<i class="label2">使用示例</i>如果原假设H0：u=1500为真，那么抽样取25时灯管平均寿命x服从N(u,a^2 / n)。若备择假设H1：u>1500为真，则x取值大于u的可能性就增大，x比u大的多时就拒绝原假设H0。此时取：v = (x - u) / sqrt(a^2 / n)作为检验统计量。
这里取显著性水平b=0.05，从标准正太分布N(0,1)表查得U(1-b)=1.65，从而得到临界域c={(x1,.,xn):(x'-1500)/40 >=1.65}。b为0.05表示字样符合原假设的概率为95%，0.05就对应上面说的拒真概率，依照这个概率在正太分布表中取的值所画出的区域-1.65~1.65之间就称为接受域，以外的称为拒绝域或临界域，所以按照上面临界域的计算，若子样本均值落到这个区间，就拒绝原假设(因为洛入这个区域的概率及小，而恰好发生了，所以是及具说服力的判断)。以下是几种常用检验，流程相同，只是统计变量不同。
<i class="label1">Z检验(u检验)</i>平均值差异性检验的方法,当已知标准差时,验证一组数的均值是否与某一期望值相等时,用Z检验(样本数大于30时使用)。检验同一样本中子样本与总样本平均值差异性时:z = (x-u)/s/sqrt(n);x时检验的样本平均值,u时总体样本平均值,s为总样本标准差,n为检验的样本容量。两组不同样本检测差异性时使用：z = (x1-x2)/sqrt(sa^2/n1+sb^2/n2);x1,x2时两组样本的均值,sa,sb时它们的标准差值小则说嘛两组差异显著。观察的样本数小于30时使用T检验。[参考学习地址](https://blog.csdn.net/robert_chen1988/article/details/103378351)。
<i class="label1">T检验(student检验)</i>用t分布理论来推论差异发生的概率，从而比较两个平均数的差异是否显著。t检验可分为单总体检验和双总体检验，以及配对样本检验。它与f检验、卡方检验并列。与Z检验非常相似主要用于样本数小于30时使用;
单总体t检验：单总体t检验是检验一个样本平均数与一个已知的总体平均数的差异是否显著。当总体分布是正态分布，如总体标准差未知且样本容量小于30，那么样本平均数与总体平均数的离差统计量呈t分布。公式:t = (x-u)/s/sqrt(n-1);
双总体检验：双总体t检验是检验两个样本平均数与其各自所代表的总体的差异是否显著。双总体t检验又分为两种情况，一是独立样本t检验（各实验处理组之间毫无相关存在，即为独立样本），该检验用于检验两组非相关样本被试所获得的数据的差异性；一是配对样本t检验，用于检验匹配而成的两组被试获得的数据或同组被试在不同条件下所获得的数据的差异性，这两种情况组成的样本即为相关样本。公式:t = (x1-x2)/sqrt({[(n1-1)sa^2+(n2-1)sb^2)]/(n1+n2-2)}*(1/n1 + 1/n2));
自由度的选择：检验两个样本的差异时，自由度可选样本数-1，然后任选一个p查表。大于指定值则认为两者无明显差异。即值越小相关性越大。
<i class="label1">卡方分布</i>若n个相互独立的随机变量ξ₁，ξ₂，...,ξn ，均服从标准正态分布（也称独立同分布于标准正态分布），则这n个服从标准正态分布的随机变量的平方和构成一新的随机变量，其分布规律称为卡方分布。求出卡方值再与卡方分布表对比，大于则假设成立。[学习参考地址。](https://blog.csdn.net/snowdroptulip/article/details/78770088)
<i class="label2">卡方检验</i>u检验于t检验是有关均值假设的显著性检验，卡方检验是有关方差的显著性检验。(检验定性自变量对定性因变量的相关性。假设自变量有N种取值，因变量有M种取值，考虑自变量等于i且因变量等于j的样本频数的观察值与期望的差距)公式：X^2 = Σ(O-E)^2/E ;//O观察到的实际值(如上图表1中的small项类别1中的1)E为假设下的值。j计算出卡方值后我们同上面例子中的一样取一个显著性水平0.05，查找卡方临界值表的对应值为3.841，如果计算出的卡方值大于3.841那么就拒绝原假设。<i class="green">主要用于分类变量（定义数据和定序数据），适用于频率数据的分析数据。常用于检验总体分布是否服从指定的分布的一种非参数检验的统计方法，可用于两个或多个频率间的比较、样本关联度分析和拟合优度检验等。</i>[参考学习地址。](http://blog.sina.com.cn/s/blog_13ea9a2450102ww2u.html)

### 三、数学分析知识：
1、函数极限：定义：设f为定义在[a,正无穷]的函数，A为定数，若对人给的q>0，存在正数M(>=a),使得当x>M时(因为M可以无穷大，所以x也需要趋于无穷大方向，这要求x逐渐增大f(x)趋于一个值，所以需要x>M这个条件)有：
|f(x)-A|<q。则称函数f当x区于正无穷时以A为极限，记为：lim(x趋于正无穷)f(x)=A。
2、函数连续性：定义：设函数f在某U(x0)上有定义，若lim(x->x0)f(x)=f(x0)则称f在点x0连续。
另一种表述：记sx=x-x0，称为自变量x在点x0的增量或改变量，设y0=f(x0)相应的函数y在点x0的增量记为：△y=f(x)-f(x0)=f(x0+△x)-f(x0)=y-y0		即为：lim(△x->0)△y=0
3、导数：导数的思想最初是由法国数学家费马为研究极值问题而引入的，但与其概念有直接联系的是已知运动规律求速度和已知曲线求它的曲线，从而推导出的导数概念：
定义：设函数y=f(x)在点x0的某领域内有定义，若极限：lim(x->x0)(f(x)-f(x0)) / (x-x0) 存在。这称函数f在点x0处的导数f'(x0)。还可以写作：lim(△x->0)△y / △x = lim (f(x0+△x)-f(x0)) / △x = f'(x0)。(该极限可能是该函数某点的切线斜率等等)。
基础函数的求导法则：
(sin x)'=cos x						(cos x)'=-sin x					(x^n)'=n*x^(n-1)
(a^x)'=a^x * lna					(e^x) = e^x					(loga x)'=1/(x*lna)
(lnx)'=1/x							[g(x)/h(x)]'=[g(x)'h(x)-h(x)'g(x)]/h(x)^2
[f(x)*g(x)]' = f(x)'g(x)+g(x)'f(x)			(f(g(x)))'=f(g(x))'*g(x)'    #*
4、微分：微分的引入：设一边长为x的正方形，它的面积S=x^2，若边长由x0增加△x，相应地方正方形的面积的增量为：△S=(x0+△x)^2 - x0^2 = 2x0*△x + (△x)^2。从这个例子中观察出来当给x0一个微小增量△x，由此引起的正方形面积增量△S可以近似的 用第一部分△x的线性部分来代替，由此产生的误差是一个关于△x的高阶无穷小量(△x)^2。
定义：设y=f(x)定义在点x0的某领域U(x0)上，当给x0一个增量△x，x0+△x属于U(x0)时相应得到函数的增量为：△y=f(x0+x△)-f(x0)，如果存在常数A使得△y能表示成△y=A*△x+o(△x)则称函数f在点x0可微。
所以微分是表示函数的增量的。
5、泰勒展开：
6、方向导数：导数表示函数在某个坐标轴上的变化率，而在3维和高维空间中有时想要了解函数具体在某一方向上的变化率，所以引入方向导数概念，因此其定义和导数的定义很像。
定义：设三元函数f在点p0(x0,y0,z0)的领域U(p0)内有定义,l为从点p0出发的一条射线，p(x,y,z)为线l上且含与U(p0)内的任意一点,p与p0的距离为d，若极限：lim(d趋于0的右极限)(f(p)-f(p0))/d = lim(d趋于0的右极限)f'/d则称此极限为函数f在点p0迎着l的方向导数。
【定理17.6：若函数f在点p0(x0,y0,z0)可微则f在p0沿任意方向l的方向导数都存在且：fl(p0) = fx(p0)cosa+fy(p0)cosb+fz(p0)cosc,cosa,cosb,cosc为方向l的反向余弦。证明可从距离公式开始：x-x0=d*cosa,y-y0=d*cosb,z-z0=d*cosc】#*
7、梯度：是函数在某点的3个坐标轴的变化率的统一向量表示。若f(x,y,z)在点p0(x0,y0,z0)存在对所有自变量的方向导数则称向量(fx(p0),fy(p0),fz(p0))为函数f在点p0的梯度，记做:gradf = (fx(p0),fy(p0),fz(p0)),向量gradf的长度为：|gradf| = math.sqrt(fx(p0)^2+fy(p0)^2+fz(p0)^2)。根据定理17.6记l方向上的单位向量l0=(cosa,cosb,cosc)
方向导数公式可写成:fl(p0)=gradf(p0)*l0=|gradf(p0)|*cosh  (向量相乘公式)，h为0时cosh达最大值则此时梯度为最大值，所以f在点p0可微时f在p0的梯度方向是f增长最快的地方，且沿这一方向的变化率就是梯度的模。【我们求完一个点的梯度值此时并没有加上方向(根据方向导数的定义就知道)而如果有方向就用上面推导出的了一个方向导数公式表示，所以我们手动为梯度值乘上一个值后就是向着对应的方向求梯度下降或上升。】
8、点到平面、点、线的距离：平面表达式：ax+by+cz+D=0,点p(x0,y0,z0),则距离公式为：
d=|ax0+by0+cz0+D|/sqrt(a^2+b^2+c^2)。[到点]sqrt((x1-x2)^2+(y1-y2)^2)。L：ax+by+c=0,p(x0,y0)
|ax0+by0+c|/sqrt(a^2+b^2)[点到线]
9、凸函数与凹函数：国内和国外对两者的定义是相反的，国内(根据几何图形的定义)：x1和x2是函数上的两个点，若x1与x2中间任意一点都在x1和x2连线的上方则是凸函数，反之为凹函数。国外(根据函数来定义)：若f(x)在[a,b]上连续，在(a,b)内具有一阶和二阶导数，若在(a,b)内f''(x)>0则f(x)在[a,b]上的图形是凹的，若f''(x)<0则是凸的。统一的判断方法：设函数f(x)在区间i上有定义，若对i中任意两点x1，和x2和任意r属于(0,1)都有：f(r*x1+(1-r)*x2)>=r*f(x1)+(1-r)*f(x2)则f为i上的凸函数，>号成立则称为严格凸函数，相反<=为凹函数。 
10、显函数与隐函数：显函数表达式大多是自变量的某个算式，如：y=x2+1,u=e^x等。而隐函数则是其自变量与因变量之间对应的法则写成的一个方程。如：x^2+y-2xy=0.隐函数定义如下：
设E属于R^2，函数F：E->R对于方程：F(x,y)=0如果存在i,j属于R，对任何x属于I有唯一确定的y属于j
使得(x,y)属于E，且满足上述方程，则说该方程定义了一个定义在I上值域含于J的隐函数。
11、拉格朗日乘数法： 对于非条件类的极值一般求其偏导来解(费马大定理)，对于有条件限制的求极值称为条件极值，以前的求条件极值是用消元法将条件式转变为函数式中一个已有变量来表示，然后求出稳定点求解。但不都是所有条件式中都能求出变元的表达式。先看下例：
欲求函数z=f(x,y)的极值，(x,y)受条件c:r(x,y)=0限制。设c上dianp(x0,y0)为函数f在条件c下的极值点，且在点p0某领域上条件c方程能唯一确定可微的隐函数y=g(x),那么z=f(x0,g(x0))=h(x0),由于在p0可微可得：h'(x0,y0)=fx(x0,y0)+fy(x0,y0)g'(x0)=0，假设对g(x)求导可写成：g'(x0)=rx(x0,y0)/ry(x0,y0)带入式子后得：fy(p0)ry(p0)-fy(p0)rx(p0)=0可引入一个参数表示为：
L(x,y,t)=f(x,y)+t*r(x,y)，所以对于有条件的极值可直接写成这一步，然后对各个变量求偏导：
L'x=f'x(x,y)+t*r'x(x,y)=0	L'y=f'y(x,y)+t*ry(x,y)=0	L't=t(x,y)=0 然后解出3个变量求出极值,所以拉格朗日乘数法就是将有条件的n个变量k个约束的条件极值变为求无条件约束的n+k个变量的极值问题。
其中引入的新的变量t叫做拉格朗日乘数。
12、级数和积分：
【级数】级数是指数列的项依次用加号连接起来的函数(有些函数是用其它多个函数相加表示的)。典型的级数有正项级数、交错级数、幂级数、傅里叶级数等。定义：级数是指将数列un的项u1,u2,...un
依次用加号连接起来的函数，是数项级数的简称。如：u1+u2+...+un=∑un=Sn,如果Sn有极限s则说级数收敛，否则说该级数发散。 正项级数：sm=u1+u2+...。un>=0。正负项相间的级数为交错级数。形如：∑an(x-x0)^n的级数称之为幂级数。
【积分】(微分学与数学分析里的一个核心概念)对于一个给定正实值函数，在区间(a,b)的定积分标示为该函数从a到b的函数曲线与垂线和坐标轴围成的面积。分为定积分(给定了积分式子的区间，求原函数在该区间的积分值)和不定积分(是求给定积分式子的原函数)。
13、傅里叶分析：包括傅里叶级数和傅里叶变换
[简谐震动：y=Asin(wx+L)].A:振幅、w:角频率、L：初相角、频率：T=2pi/w【傅里叶级数】
yk = Aksin(kwx+Lk) >> y = sum(Aksin(kwx+Lk)) // k是下标。(只讨论w=1的情况[w!=a则用wx代替x，对无穷多个简谐震动yk叠加后得到：a0+sum(akcos(ks)+bksin(kx))  //这是由三角函数列产生的一般形式的三角级数。])这是一个函数项级数，我们需要讨论该级数其中的一些规律：
若该级数收敛则它的和一定是一个以2pi为周期的函数。三角函数系：1,cosx,sinx,cos2x,sin2x,...
以上三角函数系中任何两个不同的函数的乘积在[-pi,pi]上的积分都是0；以上任何一个函数的平方在
[-pi,pi]上的积分都不等于0.
证明其收敛性定理如下：若级数|a0|/2 + sum(|an|+|bn|)收敛则以上级数在数轴上绝对收敛且一致收敛。>>(推理出，证明过程省略)若两个函数€,Œ在[a,b]上可积且 (a~b)intel(€(x)*Œ(x))dx=0则称函数函数€,Œ在[a,b]上是正交的。所以称三角函数系在[-pi,pi]上具有正交性。我们之所以提出此正较性是为了方便后面讨论三角级数的和函数和级数系数a0,an,bn之间的关系。傅里叶级数定理：
若在整个数轴上f(x)=a0/2+(1-↑)∑(an*cos(nx)+bn*sin(nx))其在等式右边级数一致收敛，则有：
an=1/π * (-π~π)intel(f(x)cos(ns))dx   bn=1/π * (-π~π)intel(f(x)*sin(nx))dx	  (10)
=>(证明过程省略)若f是以2π为周期且在[-π,π]上可积的函数，则按(10)计算出的an和bn称为函数f的傅里叶系数，以f的傅里叶系数为系数的称为傅里叶级数。
傅里叶变换：https://www.cnblogs.com/h2zZhou/p/8405717.html
## 2、英语
### 1、编程常用相关词汇：
regression//n,回归、复原、退化			sequence//序列、顺序	
exceed,surpass//超过					coordinate//n,坐标；adj,同等的并列的
previously//adj,以前的					cause,reason// n,原因
logistics//n,后勤学，物流					interpolate//vi,插入、篡改
weather//n,天气						average,mean//n,平均
graphics//n,图表算法，制图法				favorable//adj,有利的良好的，优惠的
capital//n,首都、省会、资本家	capital gain//资本得利，capital loss//资本损失
convert//vt,使转变						fitment//n,家具，设备，装修
invalid//adj,无效的，有病的				corps,object//n,物体
legend//n,图例，说明，传奇				subplot//n,次要情节
summary//n,adj,摘要，简易的				scalar//n,标量的
histogram//n,直方图					merge//vt,合并，吞没
config//n,配置，布局					proto//n,原型，样机
chief//n,首领,adj,主要的,adv,主要的		visor//n,遮阳板
example//n,例子,榜样					tutorial//adj,辅助的,个别指导的
operand//n,操作数，运算对象				binary//adj,二进制的
decay//vi,衰退,衰减						exponential//adj,指数的
assign//vt,赋值,指派					parameter//n,参数，参量
batch//n,一批,vt,分批处理						shuffle//v,洗牌、搅乱
transpose//v,调换、颠倒顺序					crop//v,收割,剪短,n,产量
iterable//adj,能推论的，迭代					convolution//卷积	
seniority//n,排行榜							statistics//v,统计
couplet//n,对联								integer//n,整数
slices//n,切片								shown//v,解释、表露、给予
machine learn//机器学习						artificial intelligence//人工智能
serial//adj,连续的serialize//连载				allocating//n,分配、vt,配置
resource//n,资源							exhaust//vt,耗尽,exhausted//adj,用尽的
latent//adj,潜在的							semantic//adj,语义的，语义学的
wiki//n,维基百科							corpus//n,语料库
binomial//adj,二项的binomial distribution//二项分布	assist//v,参加，有助于、协助
convole//vt,使卷，使缠绕						execute//v,执行、处死
increment//n,数量、增加						primary//adj,主要的、初级的
parity//n,平价、相等；disparity//n,不平等的		trace//vt,跟踪，探索
slash//vt,猛砍，严厉批评						scheme//n,计划，组合，体制
forbidden//adj,被禁止的,严禁的				implement//vt,实施，执行
algorithm//n,算法，运算法则					excluded//adj,排除的
patented//adj,专利的						duplicate//adj,复制的，重复的
assume//vt,承担，假定						collapse//v,倒塌，瓦解
unfolds//vt,打开，vi:展现						params//n,参数
beam//n,光线，电波;vt,发送，照射				quantity//n,量、数量、数目
utterances//n,表达，说话					architecture//n,建筑学，建筑风格
competitive//adj,竞争的，比赛的				abstrict//n,摘要
dependencies//n,依赖性，相关性				context//n,上下文，环境
solely//adv,单独地、唯一地					stack//n,堆，堆叠   capture//n,捕获
perceptron//n,感知器						postprocessor//n,后处理机
candidate//n,候选人，候补者					utterance//n,表达，说话
draft//n,草稿，汇票；//vt,起草，制定			denote//n,指示，表示
process//n,过程；//v,审核，处理				propose//n,建议，打算
sparse//adj,稀疏的，dense//adj,密集的			entities//n,实体
### 2、语法知识：
【名词所有格】名词有三个格：主格、宾格、所有格，主格与宾格形式相同所以统称为通格，名词做主语，宾语，表语时用通格。所有格形式有：'s和of所有格，举例如下：
today's paper(今天的报纸)   the title of the book.
## 3、数据结构：
### 一、线性表：
最常用，最简单的一种数据结构，一个线性表是n数据元素的有限序列，一个数据元素可以是一页书，可由若干数据项组成，这种情况下常把数据元素称为记录，含有大量记录的线性表又称文件。各编程语言中的列表型数据和线性表类似但两者定义有点区别。<i class="green">(线性表要求各元素是一致格式的，如第一个为单个元素，那么其它也必须为单个元素)</i>
### 二、栈和队列：
栈和队列也是线性表，其特殊性在于栈和队列的操作是线性表操作的子集，因此可以称为限定性的数据结构。
<i class="label1">栈</i>是限定仅在表尾进行插入或删除操作的线性表，表尾端称为栈顶，表头端称为栈底。不含元素的空表称为空栈。所以栈又称为后进先出的线性表。
<i class="label1">队列</i>和栈相反，队列是一种先进先出的线性表，它只允许在表的一端进行插入，在表的另一端进行删除元素。
### 三、串：
字符串一般简称为串，在汇编和语言的编译程序中，源程序和目标程序都是字符串数据。由0个或多个字符组成的有限序列就称为串，一般记为s='a1a2...an'。零个字符的串称为空串。
### 四、数组和广义表：
两者的定义都是一大段伪代码表示的。广义表是线性表的推广，也有人称其为列表，广义表中的数据元素可以具有不同的结构(如一个是a，一个是一个子表)，因此难以用顺序存储结构表示，通常采用链式存储结构。所以广义表比线性表更灵活。
### 五、树：
堆、栈、链表存储的数据在查找时非常费时间，而用树存储的数据可以提高查询效率树的第一层只有一个节点即根节点(没有父节点的节点)，其余为子节点，每个节点可有多个子节点和一个直接父节点。
二叉树:每个节点最多有两个子节点，第k层最多有2^(k-1)个节点，为k层的树最多有2^k-1个节点。
无序树：树中任意节点的子结点之间没有顺序关系,这种树称为无序树,也称为自由树;
有序树：树中任意节点的子结点之间有顺序关系，这种树称为有序树；
满二叉树：除最后一层无子节点外其余层节点均有两个子节点；
完全二叉树：二叉树的最后一层可以不完整但其余层的节点达到最大值且最后一层的节点全部集中在左侧。
二叉查找树(二叉排序树、二叉搜索树)：左子树上所有节点的值都小于根节点的值，右子树上所有节点的值都大于等于根节点的值，左子树和右子树上的子二叉树也均满足这种排列。树种没有节点名相同的节点。
平衡二叉树、平衡二叉树之红黑树、B树、B+树、B*树、Trie树、哈夫曼树(最优二叉树)：n个带权值的节点构成的树使得该树带权路径长最小，权值越大的树离树节点越近(???)。
树的遍历：1、前序遍历:先排中间节点再排左子树节点最后排右子树节点;2、中序遍历:先排左子树的节点再排中间节点然后排右子树节点;3、后序遍历:先排左子树节点再排右子树节点最后排中间节点。如图：
其先序遍历为ABDECF。其中序遍历为DBEAFC。其后序遍历为DEBFCA。依据其中两种遍历顺序可画画该二叉树。
http://blog.jobbole.com/111680/
### 六、图：
图是一种较线性表和树更为复杂的数据结构，图中任意两个数据元素之间都可能由关系，图是一种数据结构，加上一组基本操作就构成了抽象数据类型。图的使用非常广。
图中数据元素通常称作顶点，v,w是两个顶点，若<v,w>∈VR(两顶点之间的关系集和)，v为弧尾巴，w为弧头，此时的图称为有向图。若<v,w>∈VR必有<w,v>∈VR则此时的图为无向图。
邻接表：图的一种链式存储结构，邻接表中对图的每个顶点建立一个单链表，第1个单链表中的节点表示依附于顶点vi的边。每个节点由3个域组成：邻接点域(指示与当前节点vi邻接的点在途中的位置)、链域(指示下一条边或弧的节点)、数据域(存储和边弧相关的信息)。
其它存储方式还有：邻接矩阵、十字链表、邻接多重表。